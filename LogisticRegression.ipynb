{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPlTgIvEKpF7"
      },
      "source": [
        "#**LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbqfLJX7KE-9"
      },
      "source": [
        "##**THEORITICAL QUESTIONS:**\n",
        "### 1. **What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "\n",
        "**Answer:** Logistic Regression is a supervised learning algorithm used for **classification tasks**, predicting the probability of a binary outcome (0 or 1). Unlike Linear Regression, which predicts continuous numerical values, Logistic Regression outputs probabilities constrained between **0 and 1** using the **sigmoid function**.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **What is the mathematical equation of Logistic Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "$$\n",
        "P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n)}}\n",
        "$$\n",
        "\n",
        "Or more simply:\n",
        "\n",
        "$$\n",
        "P = \\sigma(Z) = \\frac{1}{1 + e^{-Z}}\n",
        "$$\n",
        "\n",
        "where $Z = \\beta_0 + \\sum \\beta_i X_i$\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Why do we use the Sigmoid function in Logistic Regression?**\n",
        "\n",
        "**Answer:** The sigmoid function transforms any real number into a value between **0 and 1**, which represents a **probability**. This is essential for classification problems.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **What is the cost function of Logistic Regression?**\n",
        "\n",
        "**Answer:** Logistic Regression uses **Binary Cross-Entropy (Log Loss)**:\n",
        "\n",
        "$$\n",
        "Cost = -\\frac{1}{N} \\sum \\left[ y \\cdot \\log(p) + (1-y) \\cdot \\log(1-p) \\right]\n",
        "$$\n",
        "\n",
        "where $p = \\sigma(Z)$\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **What is Regularization in Logistic Regression? Why is it needed?**\n",
        "\n",
        "**Answer:** Regularization is a technique used to **prevent overfitting** by penalizing large coefficients in the model. It keeps the model simple and generalizable.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "| Regression     | Penalty Term                | Effect                                       |    |                                                       |\n",
        "| -------------- | --------------------------- | -------------------------------------------- | -- | ----------------------------------------------------- |\n",
        "| **Ridge**      | L2 ($\\lambda \\sum \\beta^2$) | Shrinks coefficients but keeps all variables |    |                                                       |\n",
        "| **Lasso**      | L1 ((\\lambda \\sum           | \\beta                                        | )) | Some coefficients become **zero** (feature selection) |\n",
        "| **ElasticNet** | L1 + L2                     | Combines Ridge and Lasso for balance         |    |                                                       |\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **When should we use Elastic Net instead of Lasso or Ridge?**\n",
        "\n",
        "**Answer:** Use Elastic Net when:\n",
        "\n",
        "* Features are **highly correlated**.\n",
        "* You need both **feature selection** (like Lasso) and **shrinkage** (like Ridge).\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **What is the impact of the regularization parameter (C) in Logistic Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* **C is the inverse of regularization strength** (`C = 1/Î»`).\n",
        "* A **high C** means less regularization (risk of overfitting).\n",
        "* A **low C** means stronger regularization (risk of underfitting).\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **What are the key assumptions of Logistic Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* **Linearity** in the log-odds.\n",
        "* **No multicollinearity** among independent variables.\n",
        "* **Independence** of observations.\n",
        "* **Large sample size** preferred for stability.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **What are some alternatives to Logistic Regression for classification tasks?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* Decision Trees\n",
        "* Random Forest\n",
        "* Gradient Boosting (e.g., XGBoost, LightGBM)\n",
        "* Support Vector Machines (SVM)\n",
        "* K-Nearest Neighbors (KNN)\n",
        "* Naive Bayes\n",
        "* Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "### 11. **What are Classification Evaluation Metrics?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* **Accuracy**\n",
        "* **Precision**\n",
        "* **Recall (Sensitivity)**\n",
        "* **F1-Score**\n",
        "* **AUC-ROC**\n",
        "* **Log Loss**\n",
        "* **Confusion Matrix**\n",
        "\n",
        "---\n",
        "\n",
        "### 12. **How does class imbalance affect Logistic Regression?**\n",
        "\n",
        "**Answer:** Logistic Regression may be biased toward the **majority class**, leading to poor recall for the minority class. Solutions include:\n",
        "\n",
        "* **`class_weight='balanced'`** parameter\n",
        "* **SMOTE** (Synthetic Minority Oversampling Technique)\n",
        "* Focus on **Recall, Precision, F1-Score** rather than Accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### 13. **What is Hyperparameter Tuning in Logistic Regression?**\n",
        "\n",
        "**Answer:** It is the process of finding the best set of parameters like:\n",
        "\n",
        "* **C** (regularization strength)\n",
        "* **Penalty** (`l1`, `l2`, `elasticnet`)\n",
        "* **Solver** (`liblinear`, `saga`, `lbfgs`)\n",
        "  Methods used include **Grid Search**, **Random Search**, and **Bayesian Optimization**.\n",
        "\n",
        "---\n",
        "\n",
        "### 14. **What are different solvers in Logistic Regression? Which one should be used?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "| Solver        | Supports           | Best For                                 |\n",
        "| ------------- | ------------------ | ---------------------------------------- |\n",
        "| **liblinear** | L1, L2             | Small datasets, binary classification    |\n",
        "| **lbfgs**     | L2                 | Multinomial, medium-sized datasets       |\n",
        "| **newton-cg** | L2                 | Multinomial                              |\n",
        "| **sag**       | L2                 | Large datasets, fast for large samples   |\n",
        "| **saga**      | L1, L2, ElasticNet | Large datasets, multinomial, sparse data |\n",
        "\n",
        "---\n",
        "\n",
        "### 15. **How is Logistic Regression extended for multiclass classification?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* **One-vs-Rest (OvR):** Fits one binary classifier per class.\n",
        "* **Softmax (Multinomial Logistic Regression):** Models all classes simultaneously. Use `multi_class='multinomial'` with `solver='lbfgs'` or `saga`.\n",
        "\n",
        "---\n",
        "\n",
        "### 16. **What are the advantages and disadvantages of Logistic Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "| Advantages                    | Disadvantages                            |\n",
        "| ----------------------------- | ---------------------------------------- |\n",
        "| Simple and easy to interpret  | Assumes linear relationship in log-odds  |\n",
        "| Fast to train                 | Not suitable for complex non-linear data |\n",
        "| Outputs probabilities         | Sensitive to outliers                    |\n",
        "| Works well for small datasets | Struggles with multicollinearity         |\n",
        "\n",
        "---\n",
        "\n",
        "### 17. **What are some use cases of Logistic Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* Credit risk modeling\n",
        "* Email spam detection\n",
        "* Customer churn prediction\n",
        "* Disease diagnosis (e.g., cancer detection)\n",
        "* Marketing campaign response prediction\n",
        "\n",
        "---\n",
        "\n",
        "### 18. **What is the difference between Softmax Regression and Logistic Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "| Logistic Regression                | Softmax Regression                                    |\n",
        "| ---------------------------------- | ----------------------------------------------------- |\n",
        "| Used for **binary** classification | Used for **multiclass** classification                |\n",
        "| Uses **sigmoid** function          | Uses **softmax** function to generalize probabilities |\n",
        "\n",
        "---\n",
        "\n",
        "### 19. **How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* Use **OvR** when classes are somewhat independent or if simplicity is preferred.\n",
        "* Use **Softmax** when classes are **mutually exclusive**, for better probability calibration.\n",
        "\n",
        "---\n",
        "\n",
        "### 20. **How do we interpret coefficients in Logistic Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* Each coefficient $\\beta_i$ represents the **change in log-odds** of the target per unit increase in that feature.\n",
        "* The **odds ratio** is calculated as:\n",
        "\n",
        "$$\n",
        "\\text{Odds Ratio} = e^{\\beta_i}\n",
        "$$\n",
        "\n",
        "* Example: If $\\beta = 0.7$, then the odds increase by **$e^{0.7} \\approx 2$**, meaning odds **double**.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMduV1dEKwP7"
      },
      "source": [
        "##**PRACTICAL QUESTIONS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-mndHijbDcU"
      },
      "source": [
        "###**1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csFxM16JbCom",
        "outputId": "48ccf0f9-666f-4174-f41b-98b49b3ff736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiW3UI3scEoG"
      },
      "source": [
        "#**2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5PTG_EvcPMt",
        "outputId": "8c8cf753-32e4-47ed-8afa-c703efc0d09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L1 Regularized Model Accuracy: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='saga', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"L1 Regularized Model Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9M4KAGAcy0Y"
      },
      "source": [
        "###**3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression (penalty='l2'). Print model accuracy and coefficients.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFx7KRzRc4NI",
        "outputId": "d82c325a-9130-4b57-a07b-b14d16b6284c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L2 Regularized Model Accuracy: 1.0\n",
            "Model Coefficients: [[-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            " [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            " [-0.11497673 -0.70769055  2.58813565  1.7744936 ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"L2 Regularized Model Accuracy:\", accuracy)\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pak5Oxtrc95o"
      },
      "source": [
        "###**4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUaDGoj8dCJi",
        "outputId": "d0b57474-67db-4d93-c4c7-b94775ea8115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ElasticNet Regularized Model Accuracy: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"ElasticNet Regularized Model Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J48PmyzEdJHM"
      },
      "source": [
        "###**5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fYSgqf2dPCa",
        "outputId": "d04ba021-f840-4db9-91a4-03358955f907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OvR Model Accuracy: 0.9666666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"OvR Model Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHb7JI8RdXHh"
      },
      "source": [
        "###**6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-CuTo7gddWV",
        "outputId": "61e5fc25-c851-4be9-822c-26f9380c77e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': 1, 'l1_ratio': 0, 'penalty': 'l1'}\n",
            "Best Cross-Validated Accuracy: 0.975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(solver='saga', max_iter=500)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'l1_ratio': [0, 0.5, 1]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlCYmI5kdzDR"
      },
      "source": [
        "###**7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruBmvPHyd3bo",
        "outputId": "8d719921-71a5-4858-d232-d90ed06b10f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Accuracy for each fold: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
            "Average Accuracy: 0.9666666666666668\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-Validation Accuracy for each fold:\", scores)\n",
        "print(\"Average Accuracy:\", np.mean(scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWJ3bJWLf6SA"
      },
      "source": [
        "###**8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ilhF0vPLszSD",
        "outputId": "8a59e945-f654-4219-c849-868727d5fc37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your CSV file:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c1f60c6-7d6c-4cc4-ae34-048c9d832a78\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9c1f60c6-7d6c-4cc4-ae34-048c9d832a78\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Upload your CSV file:\")\n",
        "    uploaded = files.upload()\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "except:\n",
        "    file_name = 'data.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(file_name)\n",
        "print(\"\\nDataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Shape:\", df.shape)\n",
        "print(\"Missing Values:\\n\", df.isnull().sum())\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nModel Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgTGjbzpiBSG"
      },
      "source": [
        "###**9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBnKO0eBjVGP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Upload your CSV file:\")\n",
        "    uploaded = files.upload()\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "except:\n",
        "    file_name = 'extended_logistic_data.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(file_name)\n",
        "X = df[['Age', 'Salary']]\n",
        "y = df['Purchased']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "rand_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=3, random_state=42)\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", rand_search.best_params_)\n",
        "print(\"Best Cross-Validated Accuracy:\", rand_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwAJd6PLjcaq"
      },
      "source": [
        "###**10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHhFVF3bXJxA"
      },
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=500))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "print(\"One-vs-One Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_q_C8AmkNFk"
      },
      "source": [
        "###**11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LYf5YGeXUWi"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnpc025VXayG"
      },
      "source": [
        "###**12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmLcVxGhXdvY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAr-OX-nXq5A"
      },
      "source": [
        "###**13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFlzK2L3XsQd"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(class_weight='balanced', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy (Balanced):\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FLadftxXxMs"
      },
      "source": [
        "###**14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXU-xF1iX05y"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df = sns.load_dataset(\"titanic\")\n",
        "df = df[[\"age\", \"fare\", \"sex\", \"survived\"]].dropna(subset=[\"sex\"])\n",
        "\n",
        "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "df[[\"age\", \"fare\"]] = imputer.fit_transform(df[[\"age\", \"fare\"]])\n",
        "\n",
        "X = df[[\"age\", \"fare\", \"sex\"]]\n",
        "y = df[\"survived\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Titanic Dataset Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on3S5OgrYDMw"
      },
      "source": [
        "###**15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfHhb5peYQma"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "model1 = LogisticRegression(max_iter=500)\n",
        "model1.fit(X_train, y_train)\n",
        "acc1 = accuracy_score(y_test, model1.predict(X_test))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model2 = LogisticRegression(max_iter=500)\n",
        "model2.fit(X_train_scaled, y_train)\n",
        "acc2 = accuracy_score(y_test, model2.predict(X_test_scaled))\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc1)\n",
        "print(\"Accuracy with scaling:\", acc2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MngRNjQzYdAC"
      },
      "source": [
        "###**16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJqTzst7Yhf8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "auc = roc_auc_score(y_test, y_probs)\n",
        "print(\"ROC-AUC Score:\", auc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXBINS6KYg4c"
      },
      "source": [
        "###**17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2waRe63QYprK"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(C=0.5, max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy with C=0.5:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En0-CuIfY1Cn"
      },
      "source": [
        "###**18. Write a Python program to train Logistic Regression and identify important features based on model coefficients.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ93TiPpY2ng"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "features = X.columns\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "for f, c in zip(features, coefficients):\n",
        "    print(f\"{f}: {c:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIq3irMTY7LD"
      },
      "source": [
        "###**19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa Score.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59VtnXKDZCbs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen's Kappa Score:\", kappa)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JROsOiCIZE5O"
      },
      "source": [
        "###**20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR2CKVq8aKZ4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiINyjdaaPBS"
      },
      "source": [
        "###**21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCN_C3qNaU1O"
      },
      "outputs": [],
      "source": [
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=500)\n",
        "    model.fit(X_train, y_train)\n",
        "    acc = model.score(X_test, y_test)\n",
        "    print(f\"Accuracy with solver '{solver}': {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cTRVZsBaXxT"
      },
      "source": [
        "###**22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsG1Rh-uaayy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfOXO5uuaddn"
      },
      "source": [
        "###**23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oBRdtMxahVS"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "model_raw = LogisticRegression(max_iter=500)\n",
        "model_raw.fit(X_train, y_train)\n",
        "acc_raw = model_raw.score(X_test, y_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=500)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "acc_scaled = model_scaled.score(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Accuracy (raw data):\", acc_raw)\n",
        "print(\"Accuracy (standardized data):\", acc_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nblxPzvpalwe"
      },
      "source": [
        "###**24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWez3uhEapLJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best C:\", grid.best_params_['C'])\n",
        "print(\"Best Cross-Validated Accuracy:\", grid.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WG0VMfar04"
      },
      "source": [
        "###**25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7GaNK-fawLh"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "joblib.dump(model, \"logistic_model.pkl\")\n",
        "\n",
        "loaded_model = joblib.load(\"logistic_model.pkl\")\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy from loaded model:\", acc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}